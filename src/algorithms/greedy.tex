\documentclass{standalone}
\begin{document}

\section{Greedy}

The greedy algorithm design paradigm produces straightforward and fast solutions to
certain problems. Usually, however, greedy algorithms do not produce correct
results, and great care must be taken to prove their correctness.

In general, the strategy is to choose a locally optimal solution in the hopes
that it produces a globally optimal output. Proofs of correctness and optimality
usually involve an exchange argument and/or induction.

\subsection{Dijkstra's Shortest Path Algorithm}

The canonical greedy algorithm. Dijkstra's algorithm computes the shortest paths
from a starting vertex by choose the least costly edge spanning a graph "cut"
or partition incident to the visited nodes. In other words, greedily choose the
edge which minimizes the current distance traveled.

\begin{figure}[h]
  \centering
  \begin{tikzpicture}[
  vertex/.style={circle, draw, fill=white, thick, minimum size=15, scale=1.5},
  ]

  % Vertices
  \node[vertex] (S) {$S$};
  \node[vertex] (V) [above right=of S] {$V$};
  \node[vertex] (W) [below right=of S] {$W$};
  \node[vertex] (T) [below right=of V] {$T$};

  % Edges
  \draw[->, thick] (S) to node[above] {1} (V);
  \draw[->, thick] (S) to node[below] {4} (W);
  \draw[->, thick] (V) to node[right] {2} (W);
  \draw[->, thick] (V) to node[above] {6} (T);
  \draw[->, thick] (W) to node[below] {3} (T);
  \end{tikzpicture}
  \caption{Weighted, directed graph}
  \label{fig:dijkstra1}
\end{figure}

The shortest path algorithm outputs the following when starting from $S$:

\begin{tabular}{ |c|c| }
  \hline
  Vertex & Shortest Path \\
  \hline
  S & 0 \\
  \hline
  V & 1 \\
  \hline
  W & 3 \\
  \hline
  T & 6 \\
  \hline
\end{tabular}

\begin{algorithm}
\caption{Dijkstra's Shortest-Path}
\begin{algorithmic}
  \Require $G = (V, E)$ has nonnegative edge weights
  \State $X = \{s\}$
  \State len(s) = 0, len(v) = $+\infty$ for every $v \neq s$ \\
  \While{There exists an edge $(v, w) \; v \in X, w \not \in X$ }
    \State $(v', w')$ = edge minimizing $len(v) + l_{vw}$
    \State Add $w'$ to $X$
    \State len(w') = len(v') + $l_{v'w'}$ \\
  \Return len
  \EndWhile
\end{algorithmic}
\end{algorithm}

The proof of Dijkstra's shortest-path algorithm differs from that of Prim's and
Kruskal's in that it proceeds by basic induction rather than presenting a proof
by contradiction and exchange argument\footnote{Consequently, I find this proof
to be slightly more difficult}.

First, a precise statement of the theorem:

\begin{theorem} \label{thm:dijkstra}
  For every directed graph $G = (V, E)$, for every starting vertex $s \in V$,
  Dijkstra's shortest-path algorithm outputs the distance of the shortest paths
  from $s$ to every (reachable) $v \in V$.
\end{theorem}

\begin{proof}[Proof of Dijkstra's Shortest-Path Algorithm] \label{prf:dijkstra}
  Let $k$ be the current iteration of the while loop in Dijkstra's algorithm,
  that is, the $k$th choice of vertex, say, $v$ to be added to the solution.
  During this iteration, the shortest distance $dist[v]$ from $s$ is computed.
  The goal of this proof is to show that every iteration of the algorithm gives
  the correct distance from $s$ for all vertices.

  Proceeding by induction, for $k = 1$ the computed distance from the starting
  vertex $s$ to itself is 0, which is clearly correct. Now assume the correct
  distance is computed for all $k = 1, 2, \dots n-1$, and consider the moment
  the algorithm must choose the $n$th vertex, call it $u$, to add to the
  solution and let the edge chosen by the algorithm be labeled $(v, u)$.

  By the algorithm, $u$'s distance is computed to be:

  \[
    dist[u] = dist[v] + length_{vu}
  \]

  To show that this is indeed the shortest path from $s$ to $u$, consider an
  arbitrary path $P$ from $s$ to $u$. We will show the length of this path is
  at least the value produced by Dijkstra's algorithm. We can deduce that $P$
  must be comprised of three segments:

  \begin{itemize}
    \item A prefix of vertices already processed
    \item At least one edge crossing the cut of visited and unvisited nodes
    \item A path consisting of unvisited nodes that reaches $u$
  \end{itemize}

  \begin{figure}
    \centering
    \begin{tikzpicture}[outer sep=auto]
      \graph[nodes={draw, circle, fill=white, thick, minimum size=15, scale=1.5}] {
        s -> a -> b -> u
      };
    \end{tikzpicture}
    \caption{Arbitrary shortest path}
    \label{fig:shortest_path}
  \end{figure}

  Let $(a, b)$ be the edge in $P$ bridging the aforementioned cut. It suffices
  to compute a lower bound for the length of $P$. The first segment consisting
  of a path from $s$ to $a$ has length $dist[a]$. By the inductive hypothesis,
  each vertex in the first segment has its correct shortest distance recorded.
  The segment consisting of only the edge $(a, b)$ has length $length_{ab}$.
  Finally, the final segment must be non-negative due to the restrictions the
  algorithm imposes on the input graph.

  \[
    len(P) \geqslant dist[a] + length_{ab}
  \]

  The final step in the proof makes use of the fact that Dijkstra's algorithm
  always chooses the edge which minimizes the sum of a candidate path's prefix
  and the edge cross the cut. In other words, we have shown:

  \[
    dist[u] + length_{uw} \leqslant dist[a] + length_{ab} \leqslant len(P)
  \]

  therefore, the path chosen by the algorithm is always the shortest such path.
\end{proof}

\subsubsection{Analysis}

The cost of repeatedly selecting the minimum edge via brute force dominates the runtime of the algorithm. For $G = (V, E)$, we traverse $|V|$ nodes, each time performing $O(|E|)$ work to select the minimum edge crossing the cut. Therefore, the naive version of Dijkstra's runs in $O(|E||V|)$.

Using a [[Heap]] this algorithm can be sped up significantly, achieving $O((|E| + |V|)\log|V|)$ runtime.

\subsection{Prim's MST Algorithm}

Prim's algorithm for computing a minimum-spanning tree. The algorithm functions almost identically to Dijkstra's algorithm in that the minimum incident edge is always chosen for the solution.

\begin{center}
  \begin{tikzpicture}[
  vertex/.style={circle, draw, fill=white, thick, minimum size=15, scale=1.5},
  ]

  % Vertices
  \node[vertex] (a) {$a$};
  \node[vertex] (b) [right=of a] {$b$};
  \node[vertex] (c) [below=of a] {$c$};
  \node[vertex] (d) [below=of b] {$d$};

  % Edges
  \draw[-, thick] (a) to node[above] {1} (b);
  \draw[-, thick] (a) to node[above] {3} (d);
  \draw[-, thick] (a) to node[left] {4} (c);
  \draw[-, thick] (b) to node[right] {2} (d);
  \draw[-, thick] (c) to node[below] {5} (d);
  \end{tikzpicture}
\end{center}

\begin{algorithm}
\caption{Prim's MST Algorithm}
\begin{algorithmic}
  \State $X = \{s\}$
  \State $T = \emptyset$
  \While{There is an edge $(v, w)$ s.t $v \in X$, $w \not \in X$}
    \State $(v', w')$ = minimum cost edge \\
    \State Add $w'$ to $X$
    \State Add $(v', w')$ to $T$
  \EndWhile
  \Return $T$
\end{algorithmic}
\end{algorithm}

\subsubsection{Analysis}

Once again the cost of repeatedly selecting the minimum edge dominates the
runtime of the algorithm leading to $O(|V||E|)$ worst-case runtime.

We can employ the same technique of using a Heap as in Dijkstra's algorithm to
achieve a runtime of $O(|E|\log|V|)$.

\subsection{Kruskal's MST Algorithm}

Kruskal's algorithm adopts a different approach, instead opting to choose the
minimum edge that would not introduce a cycle.

\begin{tikzpicture}[
vertex/.style={circle, draw, fill=white, thick, scale=2},
]

% Vertices
\node[vertex] (a) {$a$};
\node[vertex] (b) [right=of a] {$b$};
\node[vertex] (c) [below=of a] {$c$};
\node[vertex] (d) [below=of b] {$d$};

% Edges
\draw[-, thick] (a) to node[above] {1} (b);
\draw[-, thick] (a) to node[above] {3} (d);
\draw[-, thick] (a) to node[left] {4} (c);
\draw[-, thick] (b) to node[right] {2} (d);
\draw[-, thick] (c) to node[below] {5} (d);
\end{tikzpicture}

Kruskal's algorithm would execute the following steps:

\begin{enumerate}
  \item Choose $(a, b)$, since it is the minimum cost edge
  \item Choose $(b, d)$, since no cycle is produced
  \item Choose $(d, e)$, since $(a, c)$ would produce a cycle
  \item The chosen edges form a spanning tree of minimum cost!
\end{enumerate}

\begin{figure}[h]
  \centering
  \begin{tikzpicture}[
  vertex/.style={circle, draw, fill=white, thick, minimum size=1.5, scale=1.5},
  ]

  % Vertices
  \node[vertex] (a) {$a$};
  \node[vertex] (b) [right=of a] {$b$};
  \node[vertex] (c) [below=of a] {$c$};
  \node[vertex] (d) [below=of b] {$d$};

  % Edges
  \draw[-, thick] (a) to node[above] {1} (b);
  \draw[-, thick] (a) to node[left] {4} (c);
  \draw[-, thick] (b) to node[right] {2} (d);
  \end{tikzpicture}
  \caption{Minimum spanning tree}
  \label{fig:kruskal-mst}
\end{figure}

In a real program, we sort the edges of the input graph $G$ by weight as a
pre-processing step to avoid quadratic searches for successive minima.

\begin{algorithm}
\caption{Kruskal's Algorithm}
\begin{algorithmic}
  \State $T = \emptyset$
  \State sort $E$ by edge weight \\
  \For{$(v, w) \in E$}
    \If{$(v, w)$ does not produce a cycle in $T$}
      \State add $(v, w)$ to $T$ \\
    \EndIf
  \EndFor
  \Return $T$
\end{algorithmic}
\end{algorithm}

\subsubsection{Analysis}

Sorting the edges takes $O(n\log n)$ time. Cycle detection in the inner loop
dominates the runtime of naive Kruskal's and therefore the overall runtime is
subject to the implementation details. For a brute-force cycle detection
approach, the inner loop runs $O(|E||E + V|) = O(|E||V|)$ time.

By using a Union-Find data structure, we can dramatically improve the runtime.
In particular by implementing optimizations such as Path Compression and
Union-by-Rank

> TODO: Do the detailed analysis later, (Inverse Ackermann)

\subsection{Huffman Codes}

Invented by David Huffman in the 50s as a way to compute the optimal prefix-free
variable length encoding for a (mathematical) language $\sum$. The algorithm
constructs a tree from the "bottom up", repeatedly merging the least frequently
occurring codes in order to ensure the most frequently occurring have minimum
possible depth.

\begin{algorithm}
\caption{Huffman Encoding}
\begin{algorithmic}
  \State $H = \emptyset$
  \For{symbol $\sigma \in \sum$}
    \State ${T_\sigma} = (\sigma, P_\sigma)$
    \State $H = H \cup T_\sigma$
  \EndFor
  \While{There is more than one $T_\sigma \in H$}
    \State $T_1$ = tree with minimum frequency
    \State $T_2$ = tree with 2nd smallest frequency
    \State $T_3$ = \Call{MergeTrees}{$T_1, T_2$}
    \State $H = H \cup T_3$ \\\\
  \EndWhile
\end{algorithmic}
\end{algorithm}

For example, given the frequencies:

\begin{tabular}{ |c|r| }
  \hline
  Symbol & Frequency \\
  \hline
  a & 0.60 \\
  \hline
  b & 0.25 \\
  \hline
  c & 0.10 \\
  \hline
  d & 0.05 \\
  \hline
\end{tabular}

Huffman's greedy algorithm will produce the following encoding tree

\begin{figure}
  \centering
  \begin{tikzpicture}[
  vertex/.style={circle, draw, fill=white, thick, minimum size=15, scale=1.5},
  ]

  % Vertices
  \node[vertex] (r1) {};
  \node[vertex] (a) [below left=of r1] {$a$};
  \node[vertex] (r2) [below right=of r1] {};

  \node[vertex] (b) [below left=of r2] {$b$};
  \node[vertex] (r3) [below right=of r2] {};

  \node[vertex] (c) [below left=of r3] {$c$};
  \node[vertex] (d) [below right=of r3] {$d$};

  % Edges
  \draw[-, thick] (r1) to node[above left] {0} (a);
  \draw[-, thick] (r1) to node[above right] {1} (r2);

  \draw[-, thick] (r2) to node[above left] {0} (b);
  \draw[-, thick] (r2) to node[above right] {1} (r3);

  \draw[-, thick] (r3) to node[above left] {0} (c);
  \draw[-, thick] (r3) to node[above right] {1} (d);
  \end{tikzpicture}
  \caption{The output of Huffman's greedy algorithm}
  \label{fig:huffman_tree}
\end{figure}

which ensures that symbol $a$, the most frequently encountered will be the quickest to encode and decode since its depth in minimized in the output.

\subsubsection{Analysis}

Preprocessing the nodes can be done quickly in $O(n)$ time. The inner loop of the algorithm is bound by the time it takes to select a minimum, therefore, repeated brute-force searching for minima each iteration leads to $O(n^2)$ runtime.

Once again, however, a [[Heap]] can be used to retrieve the minimum trees in constant time with $O(\log n)$ re-balance operations. This results in a much better runtime of $O(n \log n)$.

\end{document}
