
# Calculus of Taylor Polynomials

[[Taylor Polynomial]]s have the helpful property of closure under integration and differentiation and also exhibit linearity. This allows us to create other Taylor formulas using one that is known.

> [!tip]
> See [[Cheatsheet#Taylor Polynomials]] for useful examples

## Properties of The Taylor Operation

> [!abstract] Properties of the Taylor Operation
> - Linearity:
> $$
> T_n(c_1 f + c_2 g) = c_1T_n(f) + c_2T_n(g)
> $$
> - Closure under Differentiation:
> $$
> (T_n f)' = T_{n-1}(f')
> $$
> - Closure under Integration:
> $$
> \int_a^x T_nf(t) \; dt = T_{n+1} g(x) \; \text{where} \; g(x) = \int_a^x f(t) \; dt
> $$
>
> Proof.
> The proof of these properties follows from the fact that Taylor polynomials are uniquely defined (by previous theorem) and by the fact that the left and right hand sides are of equal degree and whose derivatives all agree for all $x$. Thus by definition of a Taylor Polynomial, the identities hold under the circumstances indicated.
>
> $\blacksquare$

An additional property immediately follows from above:

> [!abstract] Substitution Property
> Let $g(x) = f(cx)$ where $c$ is a constant. Then,
> $$
> T_n g(x; a) = f(cx; ca)
> $$
>
> In particular, when $a = 0$, we have $T_n g(x) = f(cx)$.
>
> Proof.
> Assume $g(x) = f(cx)$ and differentiate both sides $k$ times to get:
> $$
> g^{(k)} (x) = c^k f^{(k)}(cx)
> $$
> Then by definition of a Taylor Polynomial we have:
> $$
> T_n g(x)
> = \sum_{k=0}^n \frac {g^{(k)}(a)} {k!} (x-a)^k
> = \sum_{k=0}^n \frac {f^{(k)}(ca)} {k!} \cdot c^k(x - a)^k
> = T_n f(cx;ca)
> $$
>
> $\blacksquare$

A final theorem is useful for simplifying the computation of Taylor polynomials:

> [!abstract] Theorem
> Let $P_n$ be a polynomial of degree $\leqslant n$ and $f, g$ be functions with order $n$ derivatives at $x = 0$. Also assume:
> $$
> f(x) = P^n(x) + x^n g(x), \;
> \text{where} \; g(x) \to 0, \; \text{as} \; x \to 0
> $$
>
> Then $P_n$ is the Taylor Polynomial generated by $f$ at $x = 0$.
>
> Proof.
> Define $h(x) = f(x) - P_n(x)$ and notice by the product rule the first $k$ derivatives of $x^n g(x)$ are of the form:
> $$
> \begin{array}{c c}
> h'(x) = & nx^{n-1}g(x) + g'(x) x^n \\
> h''(x) = & n(n-1)x^{n-2}g(x) + nx^{n-1}g'(x) + nx^{n-1}g'(x) + g''(x) x^n \\
> \dots & \dots \\
> \text{and so on}
> \end{array}
> $$
>
> Hence for $n$ derivatives at $x = 0$, we have $h^{(n)}(x) = 0 \implies P_n(x) = f(x)$.
>
> $\blacksquare$

The preceding theorem shows how we may obtain a Taylor polynomial by recognizing a series whose highest degree term is some form of $x^n g(x)$. This works because of the assumption that $g(x) \to 0$ and so would become "infinitely more negligible" in the approximation of $f(x)$.